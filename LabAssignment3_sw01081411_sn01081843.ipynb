{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f56ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Members:\n",
    "# SARVENTTHINI - SW01081411\n",
    "# DANESH THEVAR - SN01081843\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03b609a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ba3593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fccca205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data (use only the ‘text’ column)\n",
    "data = pd.read_csv('news_dataset.csv')\n",
    "texts = data['text'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2299c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and non-alphabetic characters\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and single character words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07dcc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to the dataset\n",
    "processed_texts = [preprocess(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e51c9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in processed_texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08a4e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform LDA using Gensim\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics=4, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28fccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the LDA model using Coherence score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_texts, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d56be480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.010*\"file\" + 0.008*\"edu\" + 0.007*\"db\" + 0.007*\"window\" + 0.006*\"system\" + 0.005*\"use\" + 0.005*\"program\" + 0.005*\"com\" + 0.005*\"mail\" + 0.005*\"available\"\n",
      "Topic 1: 0.006*\"00\" + 0.005*\"10\" + 0.004*\"25\" + 0.004*\"11\" + 0.004*\"55\" + 0.004*\"17\" + 0.003*\"15\" + 0.003*\"16\" + 0.003*\"14\" + 0.003*\"12\"\n",
      "Topic 2: 0.007*\"would\" + 0.007*\"one\" + 0.005*\"people\" + 0.004*\"know\" + 0.004*\"like\" + 0.004*\"time\" + 0.004*\"think\" + 0.003*\"get\" + 0.003*\"key\" + 0.003*\"year\"\n",
      "Topic 3: 0.435*\"ax\" + 0.032*\"max\" + 0.008*\"g9v\" + 0.007*\"b8f\" + 0.006*\"a86\" + 0.005*\"pl\" + 0.005*\"145\" + 0.004*\"1d9\" + 0.003*\"0t\" + 0.003*\"1t\"\n",
      "\n",
      "Coherence Score: 0.7811\n"
     ]
    }
   ],
   "source": [
    "# Print the topics and coherence score\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(f\"Topic {topic[0]}: {topic[1]}\")\n",
    "\n",
    "print(f\"\\nCoherence Score: {coherence_lda:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a922b188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretation of Coherence Score:\n",
      "The coherence score is a measure of how interpretable the topics are to humans. It\n",
      "considers the degree of semantic similarity between high-scoring words in the topics. \n",
      "A higher coherence score typically indicates more meaningful and coherent topics. \n",
      "In this model, the coherence score is 0.7811, which suggests that the topics identified\n",
      "by the LDA model are reasonably coherent. However, this score is context-dependent \n",
      "and should be interpreted with consideration to the specific dataset and domain.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interpretation of the result\n",
    "interpretation = \"\"\"\n",
    "Interpretation of Coherence Score:\n",
    "The coherence score is a measure of how interpretable the topics are to humans. It\n",
    "considers the degree of semantic similarity between high-scoring words in the topics. \n",
    "A higher coherence score typically indicates more meaningful and coherent topics. \n",
    "In this model, the coherence score is {:.4f}, which suggests that the topics identified\n",
    "by the LDA model are reasonably coherent. However, this score is context-dependent \n",
    "and should be interpreted with consideration to the specific dataset and domain.\n",
    "\"\"\".format(coherence_lda)\n",
    "\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a64fb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848703cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
